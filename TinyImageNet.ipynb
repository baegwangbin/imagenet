{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('words.txt').readlines()\n",
    "for i in range(len(words)):\n",
    "    words[i] = words[i][:-1].split('\\t')\n",
    "    \n",
    "words = dict(words)\n",
    "    \n",
    "wnids = open('wnids.txt').readlines()\n",
    "for i in range(len(wnids)):\n",
    "    wnids[i] = wnids[i][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, `words` can be used to look up the image labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n02124075 Egyptian cat\n",
      "n04067472 reel\n",
      "n04540053 volleyball\n",
      "n04099969 rocking chair, rocker\n",
      "n07749582 lemon\n",
      "n01641577 bullfrog, Rana catesbeiana\n",
      "n02802426 basketball\n",
      "n09246464 cliff, drop, drop-off\n",
      "n07920052 espresso\n",
      "n03970156 plunger, plumber's helper\n",
      "n03891332 parking meter\n",
      "n02106662 German shepherd, German shepherd dog, German police dog, alsatian\n",
      "n03201208 dining table, board\n",
      "n02279972 monarch, monarch butterfly, milkweed butterfly, Danaus plexippus\n",
      "n02132136 brown bear, bruin, Ursus arctos\n",
      "n04146614 school bus\n",
      "n07873807 pizza, pizza pie\n",
      "n02364673 guinea pig, Cavia cobaya\n",
      "n04507155 umbrella\n",
      "n03854065 organ, pipe organ\n",
      "n03838899 oboe, hautboy, hautbois\n",
      "n03733131 maypole\n",
      "n01443537 goldfish, Carassius auratus\n",
      "n07875152 potpie\n",
      "n03544143 hourglass\n",
      "n09428293 seashore, coast, seacoast, sea-coast\n",
      "n03085013 computer keyboard, keypad\n",
      "n02437312 Arabian camel, dromedary, Camelus dromedarius\n",
      "n07614500 ice cream, icecream\n",
      "n03804744 nail\n",
      "n04265275 space heater\n",
      "n02963159 cardigan\n",
      "n02486410 baboon\n",
      "n01944390 snail\n",
      "n09256479 coral reef\n",
      "n02058221 albatross, mollymawk\n",
      "n04275548 spider web, spider's web\n",
      "n02321529 sea cucumber, holothurian\n",
      "n02769748 backpack, back pack, knapsack, packsack, rucksack, haversack\n",
      "n02099712 Labrador retriever\n",
      "n07695742 pretzel\n",
      "n02056570 king penguin, Aptenodytes patagonica\n",
      "n02281406 sulphur butterfly, sulfur butterfly\n",
      "n01774750 tarantula\n",
      "n02509815 lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens\n",
      "n03983396 pop bottle, soda bottle\n",
      "n07753592 banana\n",
      "n04254777 sock\n",
      "n02233338 cockroach, roach\n",
      "n04008634 projectile, missile\n",
      "n02823428 beer bottle\n",
      "n02236044 mantis, mantid\n",
      "n03393912 freight car\n",
      "n07583066 guacamole\n",
      "n04074963 remote control, remote\n",
      "n01629819 European fire salamander, Salamandra salamandra\n",
      "n09332890 lakeside, lakeshore\n",
      "n02481823 chimpanzee, chimp, Pan troglodytes\n",
      "n03902125 pay-phone, pay-station\n",
      "n03404251 fur coat\n",
      "n09193705 alp\n",
      "n03637318 lampshade, lamp shade\n",
      "n04456115 torch\n",
      "n02666196 abacus\n",
      "n03796401 moving van\n",
      "n02795169 barrel, cask\n",
      "n02123045 tabby, tabby cat\n",
      "n01855672 goose\n",
      "n01882714 koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus\n",
      "n02917067 bullet train, bullet\n",
      "n02988304 CD player\n",
      "n04398044 teapot\n",
      "n02843684 birdhouse\n",
      "n02423022 gazelle\n",
      "n02669723 academic gown, academic robe, judge's robe\n",
      "n04465501 tractor\n",
      "n02165456 ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle\n",
      "n03770439 miniskirt, mini\n",
      "n02099601 golden retriever\n",
      "n04486054 triumphal arch\n",
      "n02950826 cannon\n",
      "n03814639 neck brace\n",
      "n04259630 sombrero\n",
      "n03424325 gasmask, respirator, gas helmet\n",
      "n02948072 candle, taper, wax light\n",
      "n03179701 desk\n",
      "n03400231 frying pan, frypan, skillet\n",
      "n02206856 bee\n",
      "n03160309 dam, dike, dyke\n",
      "n01984695 spiny lobster, langouste, rock lobster, crawfish, crayfish, sea crawfish\n",
      "n03977966 police van, police wagon, paddy wagon, patrol wagon, wagon, black Maria\n",
      "n03584254 iPod\n",
      "n04023962 punching bag, punch bag, punching ball, punchball\n",
      "n02814860 beacon, lighthouse, beacon light, pharos\n",
      "n01910747 jellyfish\n",
      "n04596742 wok\n",
      "n03992509 potter's wheel\n",
      "n04133789 sandal\n",
      "n03937543 pill bottle\n",
      "n02927161 butcher shop, meat market\n",
      "n01945685 slug\n",
      "n02395406 hog, pig, grunter, squealer, Sus scrofa\n",
      "n02125311 cougar, puma, catamount, mountain lion, painter, panther, Felis concolor\n",
      "n03126707 crane\n",
      "n04532106 vestment\n",
      "n02268443 dragonfly, darning needle, devil's darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk\n",
      "n02977058 cash machine, cash dispenser, automated teller machine, automatic teller machine, automated teller, automatic teller, ATM\n",
      "n07734744 mushroom\n",
      "n03599486 jinrikisha, ricksha, rickshaw\n",
      "n04562935 water tower\n",
      "n03014705 chest\n",
      "n04251144 snorkel\n",
      "n04356056 sunglasses, dark glasses, shades\n",
      "n02190166 fly\n",
      "n03670208 limousine, limo\n",
      "n02002724 black stork, Ciconia nigra\n",
      "n02074367 dugong, Dugong dugon\n",
      "n04285008 sports car, sport car\n",
      "n04560804 water jug\n",
      "n04366367 suspension bridge\n",
      "n02403003 ox\n",
      "n07615774 ice lolly, lolly, lollipop, popsicle\n",
      "n04501370 turnstile\n",
      "n03026506 Christmas stocking\n",
      "n02906734 broom\n",
      "n01770393 scorpion\n",
      "n04597913 wooden spoon\n",
      "n03930313 picket fence, paling\n",
      "n04118538 rugby ball\n",
      "n04179913 sewing machine\n",
      "n04311004 steel arch bridge\n",
      "n02123394 Persian cat\n",
      "n04070727 refrigerator, icebox\n",
      "n02793495 barn\n",
      "n02730930 apron\n",
      "n02094433 Yorkshire terrier\n",
      "n04371430 swimming trunks, bathing trunks\n",
      "n04328186 stopwatch, stop watch\n",
      "n03649909 lawn mower, mower\n",
      "n04417672 thatch, thatched roof\n",
      "n03388043 fountain\n",
      "n01774384 black widow, Latrodectus mactans\n",
      "n02837789 bikini, two-piece\n",
      "n07579787 plate\n",
      "n04399382 teddy, teddy bear\n",
      "n02791270 barbershop\n",
      "n03089624 confectionery, confectionary, candy store\n",
      "n02814533 beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon\n",
      "n04149813 scoreboard\n",
      "n07747607 orange\n",
      "n03355925 flagpole, flagstaff\n",
      "n01983481 American lobster, Northern lobster, Maine lobster, Homarus americanus\n",
      "n04487081 trolleybus, trolley coach, trackless trolley\n",
      "n03250847 drumstick\n",
      "n03255030 dumbbell\n",
      "n02892201 brass, memorial tablet, plaque\n",
      "n02883205 bow tie, bow-tie, bowtie\n",
      "n03100240 convertible\n",
      "n02415577 bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain sheep, Ovis canadensis\n",
      "n02480495 orangutan, orang, orangutang, Pongo pygmaeus\n",
      "n01698640 American alligator, Alligator mississipiensis\n",
      "n01784675 centipede\n",
      "n04376876 syringe\n",
      "n03444034 go-kart\n",
      "n01917289 brain coral\n",
      "n01950731 sea slug, nudibranch\n",
      "n03042490 cliff dwelling\n",
      "n07711569 mashed potato\n",
      "n04532670 viaduct\n",
      "n03763968 military uniform\n",
      "n07768694 pomegranate\n",
      "n02999410 chain\n",
      "n03617480 kimono\n",
      "n06596364 comic book\n",
      "n01768244 trilobite\n",
      "n02410509 bison\n",
      "n03976657 pole\n",
      "n01742172 boa constrictor, Constrictor constrictor\n",
      "n03980874 poncho\n",
      "n02808440 bathtub, bathing tub, bath, tub\n",
      "n02226429 grasshopper, hopper\n",
      "n02231487 walking stick, walkingstick, stick insect\n",
      "n02085620 Chihuahua\n",
      "n01644900 tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui\n",
      "n02129165 lion, king of beasts, Panthera leo\n",
      "n02699494 altar\n",
      "n03837869 obelisk\n",
      "n02815834 beaker\n",
      "n07720875 bell pepper\n",
      "n02788148 bannister, banister, balustrade, balusters, handrail\n",
      "n02909870 bucket, pail\n",
      "n03706229 magnetic compass\n",
      "n07871810 meat loaf, meatloaf\n",
      "n03447447 gondola\n",
      "n02113799 standard poodle\n",
      "n12267677 acorn\n",
      "n03662601 lifeboat\n",
      "n02841315 binoculars, field glasses, opera glasses\n",
      "n07715103 cauliflower\n",
      "n02504458 African elephant, Loxodonta africana\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(wnids)):\n",
    "    print(wnids[i], words[wnids[i]], sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read Images & Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `labels`: contains the labels that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = wnids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [] ; Y1_train = [] ; Y2_train = []\n",
    "X_val = []   ; Y1_val = []   ; Y2_val = []\n",
    "\n",
    "# create training data\n",
    "for i in range(len(labels)):\n",
    "\n",
    "    # open box data\n",
    "    train_box = open('train/{0}/{0}_boxes.txt'.format(labels[i])).readlines()\n",
    "    for j in range(len(train_box)):\n",
    "        train_box[j] = train_box[j][:-1].split('\\t')\n",
    "            \n",
    "    for k in range(450):\n",
    "\n",
    "        # add labels & boxes\n",
    "        # Y1_train.append(labels[i])\n",
    "        Y1_train.append(i)\n",
    "        Y2_train.append(list(map(int, train_box[k][1:])))\n",
    "\n",
    "        # open image\n",
    "        filename = 'train/{0}/images/{0}_{1}.jpeg'.format(labels[i], k)\n",
    "        im = np.asarray(Image.open(filename))\n",
    "        if im.shape == (64,64,3):\n",
    "            X_train.append(im)\n",
    "        elif im.shape == (64,64):\n",
    "            X_train.append(np.dstack([im,im,im]))\n",
    "        else:\n",
    "            print('something wrong with {}'.format(filename))\n",
    "\n",
    "    for l in range(50):\n",
    "        \n",
    "        # add labels & boxes\n",
    "        # Y1_train.append(labels[i])\n",
    "        Y1_val.append(i)\n",
    "        Y2_val.append(list(map(int, train_box[l+450][1:])))\n",
    "\n",
    "        # open image\n",
    "        filename = 'train/{0}/images/{0}_{1}.jpeg'.format(labels[i], l+450)\n",
    "        im = np.asarray(Image.open(filename))\n",
    "        if im.shape == (64,64,3):\n",
    "            X_val.append(im)\n",
    "        elif im.shape == (64,64):\n",
    "            X_val.append(np.dstack([im,im,im]))\n",
    "        else:\n",
    "            print('something wrong with {}'.format(filename))\n",
    "\n",
    "            \n",
    "X_train = np.stack(X_train, axis=0)\n",
    "Y1_train = np_utils.to_categorical(Y1_train, 10)\n",
    "Y2_train = np.stack(Y2_train, axis=0)\n",
    "\n",
    "X_val = np.stack(X_val, axis=0)\n",
    "Y1_val = np_utils.to_categorical(Y1_val, 10)\n",
    "Y2_val = np.stack(Y2_val, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create test data\n",
    "X_test = []  ; Y1_test = []  ; Y2_test = []\n",
    "\n",
    "val_annot = open('val/val_annotations.txt').readlines()\n",
    "for i in range(len(val_annot)):\n",
    "    val_annot[i] = val_annot[i][:-1].split('\\t')\n",
    "    \n",
    "for i in range(len(val_annot)):\n",
    "\n",
    "    if val_annot[i][1] in labels:\n",
    "        filename = 'val/images/val_{0}.jpeg'.format(i)\n",
    "        im = np.asarray(Image.open(filename))\n",
    "        \n",
    "        # Y1_test.append(val_annot[i][1])\n",
    "        Y1_test.append(labels.index(val_annot[i][1]))\n",
    "        Y2_test.append(list(map(int, val_annot[i][2:])))\n",
    "\n",
    "        if im.shape == (64,64,3):\n",
    "            X_test.append(im)\n",
    "        elif im.shape == (64,64):\n",
    "            X_test.append(np.dstack([im,im,im]))\n",
    "        else:\n",
    "            print('something wrong with {}'.format(filename))\n",
    "\n",
    "X_test = np.stack(X_test, axis=0)\n",
    "Y1_test = np_utils.to_categorical(Y1_test, 10)\n",
    "Y2_test = np.stack(Y2_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4500, 64, 64, 3), (500, 64, 64, 3), (500, 64, 64, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4500, 10), (500, 10), (500, 10))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1_train.shape, Y1_val.shape, Y1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4500, 4), (500, 4), (500, 4))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2_train.shape, Y2_val.shape, Y2_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(4, (3, 3), activation='relu', input_shape=(64, 64, 3), kernel_initializer=\"glorot_uniform\"))\n",
    "model1.add(Conv2D(4, (3, 3), activation='relu', input_shape=(64, 64, 3), kernel_initializer=\"glorot_uniform\"))\n",
    "model1.add(Conv2D(4, (3, 3), activation='relu', input_shape=(64, 64, 3), kernel_initializer=\"glorot_uniform\"))\n",
    "model1.add(MaxPooling2D())\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(10, activation='softmax', kernel_initializer=\"glorot_uniform\"))\n",
    "\n",
    "np.random.seed(0)\n",
    "model1.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adadelta())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 4)         112       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 4)         148       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 58, 58, 4)         148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 29, 29, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                33650     \n",
      "=================================================================\n",
      "Total params: 34,058\n",
      "Trainable params: 34,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      " - 12s - loss: 3.0036 - acc: 0.1189 - val_loss: 2.3145 - val_acc: 0.1220\n",
      "Epoch 2/10\n",
      " - 11s - loss: 2.2273 - acc: 0.1649 - val_loss: 2.3168 - val_acc: 0.1520\n",
      "Epoch 3/10\n",
      " - 11s - loss: 2.0749 - acc: 0.2378 - val_loss: 2.3705 - val_acc: 0.1560\n",
      "Epoch 4/10\n",
      " - 11s - loss: 1.9101 - acc: 0.3131 - val_loss: 2.5104 - val_acc: 0.1560\n",
      "Epoch 5/10\n",
      " - 11s - loss: 1.7551 - acc: 0.3773 - val_loss: 2.7669 - val_acc: 0.1760\n",
      "Epoch 6/10\n",
      " - 11s - loss: 1.6051 - acc: 0.4336 - val_loss: 2.8874 - val_acc: 0.1720\n",
      "Epoch 7/10\n",
      " - 12s - loss: 1.4654 - acc: 0.4816 - val_loss: 3.2344 - val_acc: 0.1720\n",
      "Epoch 8/10\n",
      " - 12s - loss: 1.3370 - acc: 0.5351 - val_loss: 3.4294 - val_acc: 0.1680\n",
      "Epoch 9/10\n",
      " - 11s - loss: 1.2246 - acc: 0.5764 - val_loss: 3.5459 - val_acc: 0.1920\n",
      "Epoch 10/10\n",
      " - 12s - loss: 1.1149 - acc: 0.6129 - val_loss: 3.7518 - val_acc: 0.1600\n",
      "CPU times: user 4min 24s, sys: 22.3 s, total: 4min 46s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hist1 = model1.fit(X_train, Y1_train, epochs=10, batch_size=30, validation_data=(X_val, Y1_val), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist1.history['acc'], 'b-', label=\"training\")\n",
    "plt.plot(hist1.history['val_acc'], 'r:', label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"mnist_cnn11.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "import matplotlib as mpl\n",
    "#mpl.use('Agg')\n",
    "import matplotlib.pylab as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_color_codes()\n",
    "\n",
    "mpl.rc('figure', figsize=(8, 5))\n",
    "mpl.rc('figure', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5e689cc62dd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "(X_train0, y_train0), (X_test0, y_test0) = mnist.load_data()\n",
    "X_train = X_train0[:, :, :, np.newaxis].astype('float32') / 255.0\n",
    "X_test = X_test0[:, :, :, np.newaxis].astype('float32') / 255.0\n",
    "Y_train = np_utils.to_categorical(y_train0, 10)\n",
    "Y_test = np_utils.to_categorical(y_test0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
